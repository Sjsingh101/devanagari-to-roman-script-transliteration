{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "From https://github.com/Sjsingh101/devanagari-to-roman-script-transliteration\n * branch            master     -> FETCH_HEAD\nAlready up to date.\n"
    }
   ],
   "source": [
    "!git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Hindi_OM.txt']\n"
    }
   ],
   "source": [
    "BASE_PATH = os.path.abspath('')\n",
    "path_input = os.path.join(BASE_PATH, \"data\")\n",
    "path_hindi = os.path.join(BASE_PATH, \"hindi\")\n",
    "path_english = os.path.join(BASE_PATH, \"english\")\n",
    "files = os.listdir(path_input)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in files:\n",
    "    with open(os.path.join(path_input,file_name)) as file_read:\n",
    "        data = file_read.read()\n",
    "        data = re.sub('[0-9]',' ', data)\n",
    "        data_list=data.replace('\\n',' ').replace('/',' ').replace('.',' ').replace('(',' ').replace(')',' ').replace('?',' ').replace('-',' ').replace(',',' ').replace('.',' ').replace(':',' ').split(' ') \n",
    "        data_list = [ word for word in data_list if len(word)<20 ]\n",
    "        data_list = list(filter(None, data_list))    \n",
    "    with open(os.path.join(path_hindi,file_name), 'w') as hindi_file:\n",
    "        hindi_file.writelines(\"%s\\n\" % word for word in set(data_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.reader(open(os.path.join(BASE_PATH, \"svar.csv\"), 'r'))\n",
    "vowels = {}\n",
    "for row in reader:\n",
    "\tk, v = row\n",
    "\tvowels[k] = v\n",
    "\n",
    "reader = csv.reader(open(os.path.join(BASE_PATH, \"vyanjan.csv\"), 'r'))\n",
    "consonants = {}\n",
    "for row in reader:\n",
    "\tk, v = row\n",
    "\tconsonants[k] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1671"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "len(set(data_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translitration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "7.73 ms ± 85.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
    }
   ],
   "source": [
    "str1 = \"\"\n",
    "for x in set(data_list):\n",
    "\tfor y in x.split():\n",
    "\t\tfor i in range(len(y)):\n",
    "\t\t\tif (i+1<len(y) and y[i+1].strip()==' ़'.strip()):\n",
    "\t\t\t\tc = y[i]+y[i+1]\n",
    "\t\t\t\tp=2\n",
    "\t\t\telse:\n",
    "\t\t\t\tc = y[i]\n",
    "\t\t\t\tp=1\n",
    "\t\t\tif (c in vowels.keys()):\n",
    "\t\t\t\tstr1 = str1 + vowels[c]\n",
    "\t\t\telif (c in consonants.keys()):\n",
    "\t\t\t\tif(i+p<len(y) and y[i+p] in consonants.keys()):\n",
    "\t\t\t\t\tif ((c=='झ' and i!=0) or (i!=0 and i+p+1<len(y) and y[i+p+1] in vowels.keys())): \n",
    "\t\t\t\t\t\tstr1 = str1 + consonants[c]\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tstr1 = str1 + consonants[c]+'a'\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tstr1 = str1 + consonants[c]\n",
    "\t\t\telif y[i] in ['\\n','\\t',' ','!',',','।','-',':','\\\\','_'] or c.isalnum():\n",
    "\t\t\t\tstr1 = str1 + c.replace('।','.')\n",
    "\t\tstr1 = str1 + \" \"\n",
    "\tstr1 = str1 + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_english,file_name), 'w') as eng_file:\n",
    "    eng_file.write(str1.replace(' ','').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "for file_name in files:\n",
    "    hindi = [line.strip('\\n').strip(')').strip('(').strip('।') for line in open(os.path.join(path_hindi,file_name), 'r')]    \n",
    "    english = [line.strip('\\n') for line in open(os.path.join(path_english,file_name), 'r')]\n",
    "    word_dict.update(dict(zip(english, hindi))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = str(int(datetime.timestamp(datetime.now())))\n",
    "with open(os.path.join(BASE_PATH,'data-'+timestamp+'.json'), 'w', encoding='utf-8') as final:\n",
    "    json.dump(word_dict, final, ensure_ascii=False, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bittestvirtualenv43a0c37e4d0b4ba49455dfc9b899a440",
   "display_name": "Python 3.6.9 64-bit ('test': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}