{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HxkGL82-eMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import json\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_0KnbJ9-eMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5b20fc4b-4ee7-4bb9-de18-4cfc46cdee4e"
      },
      "source": [
        "BASE_PATH = '/content/drive/My Drive/devnagri-to-roman'\n",
        "path_input = os.path.join(BASE_PATH, \"data\")\n",
        "path_hindi = os.path.join(BASE_PATH, \"hindi\")\n",
        "path_english = os.path.join(BASE_PATH, \"english\")\n",
        "files = os.listdir(path_input)\n",
        "print(files)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['454670_857975-val.txt', 'bbc-test.txt', 'bbc-train.txt', '454670_857975-train.txt', '454536_857792-train.txt', '454520_857761-valid.txt', '454536_857792-test.txt', '454520_857761-train.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwmjev3X-eMY",
        "colab_type": "text"
      },
      "source": [
        "## Data Cleaning and Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMXdcjKR-eMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_list = []\n",
        "for file_name in files:\n",
        "    with open(os.path.join(path_input,file_name)) as file_read:\n",
        "        data = file_read.read()\n",
        "        data = re.sub('[0-9]',' ', data)\n",
        "        data_list=data.replace('\\n',' ').replace('/',' ').replace('.',' ').replace('(',' ').replace(')',' ').replace('?',' ').replace('-',' ').replace(',',' ').replace('.',' ').replace(':',' ').replace('\\\"',' ').replace('\"',' ').replace('“',' ').replace('^',' ').replace('|',' ').replace('@',' ').replace('”',' ').replace('{',' ').replace('!',' ').replace('}',' ').split(' ') \n",
        "        data_list = [ word for word in data_list if len(word)<20 ]\n",
        "        data_list = [ word for word in data_list if not word.isalnum() ]\n",
        "        data_list = list(filter(None, data_list))    \n",
        "    with open(os.path.join(path_hindi,file_name), 'w') as hindi_file:\n",
        "        hindi_file.writelines(\"%s\\n\" % word for word in set(data_list))\n",
        "    b_list.extend(set(data_list))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAUSOx2G-eMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reader = csv.reader(open(os.path.join(BASE_PATH, \"svar.csv\"), 'r'))\n",
        "vowels = {}\n",
        "for row in reader:\n",
        "\tk, v = row\n",
        "\tvowels[k] = v\n",
        "\n",
        "reader = csv.reader(open(os.path.join(BASE_PATH, \"vyanjan.csv\"), 'r'))\n",
        "consonants = {}\n",
        "for row in reader:\n",
        "\tk, v = row\n",
        "\tconsonants[k] = v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAlnNWAo-eMh",
        "colab_type": "text"
      },
      "source": [
        "## Unique Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oraEKaBT-eMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cda5b948-a855-4864-d00f-9c0d1707b88c"
      },
      "source": [
        "len(set(b_list))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "602908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj25tvX1-eMl",
        "colab_type": "text"
      },
      "source": [
        "## Translitration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dpHH04U-eMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str1 = \"\"\n",
        "for x in set(b_list):\n",
        "\tfor y in x.split():\n",
        "\t\tfor i in range(len(y)):\n",
        "\t\t\tif (i+1<len(y) and y[i+1].strip()==' ़'.strip()):\n",
        "\t\t\t\tc = y[i]+y[i+1]\n",
        "\t\t\t\tp=2\n",
        "\t\t\telse:\n",
        "\t\t\t\tc = y[i]\n",
        "\t\t\t\tp=1\n",
        "\t\t\tif (c in vowels.keys()):\n",
        "\t\t\t\tstr1 = str1 + vowels[c]\n",
        "\t\t\telif (c in consonants.keys()):\n",
        "\t\t\t\tif(i+p<len(y) and y[i+p] in consonants.keys()):\n",
        "\t\t\t\t\tif ((c=='झ' and i!=0) or (i!=0 and i+p+1<len(y) and y[i+p+1] in vowels.keys())): \n",
        "\t\t\t\t\t\tstr1 = str1 + consonants[c]\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tstr1 = str1 + consonants[c]+'a'\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tstr1 = str1 + consonants[c]\n",
        "\t\t\telif y[i] in ['\\n','\\t',' ','!',',','।','-',':','\\\\','_'] or c.isalnum():\n",
        "\t\t\t\tstr1 = str1 + c.replace('।','.')\n",
        "\t\tstr1 = str1 + \" \"\n",
        "\tstr1 = str1 + \"\\n\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jolrbKmg-eMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(os.path.join(path_english,file_name), 'w') as eng_file:\n",
        "    eng_file.write(str1.replace(' ','').strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgdDfwxe-eMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_dict = {}\n",
        "hindi = set(b_list)    \n",
        "english = [line.strip('\\n') for line in open(os.path.join(path_english,file_name), 'r')]\n",
        "word_dict.update(dict(zip(english, hindi))) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35xua4OJ-eMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "timestamp = str(int(datetime.timestamp(datetime.now())))\n",
        "with open(os.path.join(BASE_PATH,'data-'+timestamp+'.json'), 'w', encoding='utf-8') as final:\n",
        "    json.dump(word_dict, final, ensure_ascii=False, indent=4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python36964bittestvirtualenv43a0c37e4d0b4ba49455dfc9b899a440",
      "display_name": "Python 3.6.9 64-bit ('test': virtualenv)"
    },
    "colab": {
      "name": "Translitration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}